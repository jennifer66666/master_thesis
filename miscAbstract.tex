\par
Generative Adversial Networks have shown great 
performance in image-to-image translation, but usually it 
requires the original domain and target domain to be similar 
to some extent. When it comes to real human faces to Anime 
faces translation, however, the exsisted methods' performance
 can look too like a real human, or like an anime that
  has no relationship with the input, because anime domain is really different with 
  human face in both structure and texture. In this paper, we 
  show that with a finetuned generator, we can generate an anime face corresponding
  to the input human face by reverse generate on both domain, and then generate on a concatenaed latent.
